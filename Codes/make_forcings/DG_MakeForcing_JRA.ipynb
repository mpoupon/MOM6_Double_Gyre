{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import os\n",
    "import glob\n",
    "import cftime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "from tqdm import tqdm\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zonal Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manual input ###\n",
    "# Paths \n",
    "jpath     = '/projects/GEOCLIM/LRGROUP/datasets_2020_Jan/JRA55-do-v1.5merge/data_origin_v1.5/' # to JRA products\n",
    "#spath     = '../../forcings/idealized_year_control/zonal_means/'  # save Zonal Mean\n",
    "#spath     = '../../forcings/warming2deg_year/zonal_means/'  # save Zonal Mean\n",
    "spath     = '../../forcings/idealized_year_cold_NHtemp/zonal_means/'  # save Zonal Mean\n",
    "\n",
    "\n",
    "# Specify which forcings to average in JRA (based on data_table)\n",
    "forcings  = ['psl', 'ts', 'huss', 'rlds', 'prra', 'prsn']\n",
    "\n",
    "# Conversion from Kelvin to Celsius\n",
    "k2C       = -273.15\n",
    "\n",
    "# Temperature threshold for land mask (in Celsius; threshold does not make a huge difference)\n",
    "tthresh  = -5\n",
    "\n",
    "# Strings to load relevant JRA data\n",
    "str90    = '*_199*'\n",
    "str20    = '*_20*'\n",
    "strYmask = '*_2019*'\n",
    "\n",
    "# Strings for filename\n",
    "strAvg   = '30yrs'\n",
    "strReg   = 'basin'\n",
    "strLand  = 'LandMask'\n",
    "\n",
    "# Boundaries for averaging time periods (30 years)\n",
    "t1      = pd.Timestamp(1990, 1, 1, 0)\n",
    "t2      = pd.Timestamp(2020, 1, 1, 0)\n",
    "\n",
    "# Time format in deposition files is different\n",
    "tC1 = cftime.DatetimeNoLeap(1990, 1, 1, 0, 0, 0, 0, has_year_zero=True)\n",
    "tC2 = cftime.DatetimeNoLeap(2020, 1, 1, 0, 0, 0, 0, has_year_zero=True)\n",
    "\n",
    "# Boundaries for spatial averaging\n",
    "# Note: land mask does not work for Africa so stay within ocean\n",
    "lat1    = 15\n",
    "lat2    = 65  \n",
    "lon1    = 295\n",
    "lon2    = 340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to generate land mask ###\n",
    "# Use temperatures at midnight on January 1, 2019\n",
    "fpath  = glob.glob(jpath + 'ts' + strYmask)\n",
    "dsR    = xr.open_mfdataset(fpath, combine='by_coords')\n",
    "\n",
    "def land_mask(lat01, lat02, lon01, lon02):\n",
    "    # Slice the dataset based on the area considered in the calculations\n",
    "    dsS  = dsR.sel(lat=slice(lat01, lat02), lon=slice(lon01, lon02))\n",
    "    mask = dsS.ts.isel(time=0).where(dsS.ts.isel(time=0)+k2C < tthresh, other = 1)  # set the ocean as 1\n",
    "    mask = mask.where(dsS.ts.isel(time=0)+k2C >= tthresh, other = 0)  # set the land as 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loop to calculate monthly zonal means ###\n",
    "for iforc in tqdm(forcings):  # loop through each forcing\n",
    "    \n",
    "    # Load 30-years of data \n",
    "    fpath  = glob.glob(jpath + iforc + str90) + glob.glob(jpath + iforc + str20)\n",
    "    ds     = xr.open_mfdataset(fpath, combine='by_coords')\n",
    "\n",
    "    # Create the land mask\n",
    "    mask = land_mask(lat1, lat2, lon1, lon2)\n",
    "\n",
    "    # Calculate zonal average\n",
    "    zAvg = ds[iforc].sel(lat=slice(lat1, lat2), \n",
    "                         lon=slice(lon1, lon2), \n",
    "                         time=slice(t1, t2)\n",
    "                        ).where(mask).mean(dim='lon', skipna=True).compute()\n",
    "\n",
    "    # Calculate monthly average\n",
    "    mAvg = zAvg.groupby(\"time.month\").mean(dim=\"time\")\n",
    "\n",
    "    # Close zAvg (help with memory?) \n",
    "    zAvg.close()\n",
    "\n",
    "    # Save monthly zonal averages for further modifications\n",
    "    fsname = '_zonal_JRA_clim' + strAvg + '_monthly_' + strReg + '_' + strLand + '.nc'\n",
    "    mAvg.to_netcdf(spath + iforc + fsname)\n",
    "\n",
    "    # Close mAvg (help with memory?) \n",
    "    mAvg.close()\n",
    "            \n",
    "    ds.close()  # close for the forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual input\n",
    "# Paths\n",
    "spath     = '../../forcings/idealized_year_control/zonal_means/'  # to saved zonal means\n",
    "gpath     = '../../forcings/idealized_year_cold_NHtemp/gridded/'  # save gridded forcing directly into INPUT folder   \n",
    "\n",
    "# Filenames in and out\n",
    "fnameLF_in  = '_zonal_JRA_clim30yrs_monthly_basin_LandMask.nc'\n",
    "fnameLF_out = '_JRA_clim30yrs_monthly_basin_LandMask_gridded.nc'\n",
    "\n",
    "# Specify which forcings to adjust\n",
    "forcings = ['psl', 'ts', 'huss', 'rlds', 'prra', 'prsn']\n",
    "scaledF  = ['prra', 'prsn']  # scale precipitation by domain area vs. real ocean\n",
    "\n",
    "# Lat and lon of forcing domain\n",
    "hres     = 0.5\n",
    "lat_out  = np.arange(15, 65.5, hres)  # from 15 to 65\n",
    "lon_out  = np.arange(300, 350.5, hres)  # from 300 to 350\n",
    "\n",
    "# Fill value\n",
    "fillval  = -1e+20  # set fill value (Raphael/Enhui: -1e+20; Elizabeth:-1.e+34)\n",
    "\n",
    "# Create a 12-month time vector \n",
    "time_m = pd.date_range(start = '1990-01-01', periods=12, freq = 'MS')+ pd.DateOffset(days=14)\n",
    "# Enhui's file has days since 1990-01-01\n",
    "time_m = np.asarray(time_m.dayofyear, dtype=np.float64)-1\n",
    "\n",
    "# Conversion from kelvin to celsius\n",
    "k2C      = -273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to save gridded forcing ###\n",
    "# 'ts', saved as 'tas' to be consistent with previous files that required Enhui's Matlab Code\n",
    "def sforc(gpath, vname, fname_out, lat_out, lon_out, time_out, f_out):\n",
    "    # Save output - this could be a function earlier in the code\n",
    "    writing = nc.Dataset(gpath + vname + fname_out, \"w\", format=\"NETCDF3_64BIT_OFFSET\")\n",
    "    time    = writing.createDimension(\"time\", None)  # sets unlimited dimension\n",
    "    yh      = writing.createDimension(\"yh\", len(lat_out))\n",
    "    xh      = writing.createDimension(\"xh\", len(lon_out))\n",
    "\n",
    "    yh     = writing.createVariable(\"yh\",\"f8\",(\"yh\"))\n",
    "    yh[:]  = lat_out\n",
    "    yh.standard_name    = \"latitude\"\n",
    "    yh.long_name        = \"latitude\"\n",
    "    yh.units            = \"degrees_north\"\n",
    "    yh.axis             = \"Y\"\n",
    "\n",
    "    xh     = writing.createVariable(\"xh\",\"f8\",(\"xh\"))\n",
    "    xh[:]  = lon_out\n",
    "    xh.standard_name    = \"longitude\"\n",
    "    xh.long_name        = \"longitude\"\n",
    "    xh.units            = \"degrees_east\"\n",
    "    xh.axis             = \"X\" ;\n",
    "\n",
    "    time    = writing.createVariable(\"time\",\"f8\",(\"time\"))\n",
    "    time[:] = time_out\n",
    "    time.standard_name   = \"time\"\n",
    "    time.long_name       = \"time\"\n",
    "    time.units           = \"days since 1900-01-01 00:00:00\" ;\n",
    "    time.calendar        = \"gregorian\" ;\n",
    "    time.axis            = \"T\" ;\n",
    "    time.modulo          = \" \" ;\n",
    "\n",
    "    var          = writing.createVariable(vname,\"f8\",(\"time\",\"yh\",\"xh\"),fill_value=fillval)\n",
    "    var[:,:,:]   = f_out\n",
    "\n",
    "    # Write information about each variable\n",
    "    # Forcing variables\n",
    "    if (vname == 'tas'):\n",
    "        var.long_name      = \"Surface Temperature\"\n",
    "        var.units          = \"K\"\n",
    "    elif (vname == 'huss'):\n",
    "        var.long_name      = \"Near-Surface Specific Humidity\"\n",
    "        var.units          = \"1\"\n",
    "    elif (vname == 'rsds'):    \n",
    "        var.long_name      = \"Surface Downwelling Shortwave Radiation\"\n",
    "        var.units          = \"W m-2\"\n",
    "    elif (vname == 'rlds'):    \n",
    "        var.long_name      = \"Surface Downwelling Longwave Radiation\"\n",
    "        var.units          = \"W m-2\"\n",
    "    elif (vname == 'prra'):\n",
    "        var.long_name      = \"Rainfall Flux\"\n",
    "        var.units          = \"kg m-2 s-1\"\n",
    "    elif (vname == 'prsn'):\n",
    "        var.long_name      = \"Snowfall Flux\"\n",
    "        var.units          = \"kg m-2 s-1\"\n",
    "\n",
    "    writing.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_filter(data, t_coupe):\n",
    "    \n",
    "    sig = data\n",
    "    fe = 1 # Fréquence d'échantillonnage (yr-1)\n",
    "    f_nyq = fe / 2.  # Fréquence de nyquist\n",
    "    fc = 1/t_coupe # Fréquence de coupure (yr-1)\n",
    "    b, a = signal.butter(4, fc/f_nyq, 'low', analog=False) #filtre de Butterworth en passe-bas\n",
    "    s_but = signal.filtfilt(b, a, sig) # Application du filtre\n",
    "    \n",
    "    return s_but"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grid forcing zonal means by repeating at each point of longitude ###\n",
    "for iforc in ['rlds']:\n",
    "    \n",
    "    # Load appropriate file & create right time vector\n",
    "    pN = xr.open_dataset(spath + iforc + fnameLF_in) \n",
    "    time_out  = time_m  # using day of year\n",
    "    fname_out = fnameLF_out\n",
    "    \n",
    "    # Create a zero array to store the forcing files\n",
    "    f_out = np.zeros((len(time_out), len(lat_out), len(lon_out)))\n",
    "             \n",
    "    # At every time step \n",
    "    for itime in np.arange(0,len(time_out)):\n",
    "        # Interpolate zonal mean to grid latitude\n",
    "        f0 = np.interp(lat_out, pN.lat, pN[iforc][itime,:])\n",
    "        #f0 = low_filter(f0, t_coupe = 80)\n",
    "        f0 = low_filter(f0, t_coupe = 80)+8.5\n",
    "        \n",
    "        # Repeat the profile everywhere in our domain\n",
    "        f_out[itime, :, :] = np.tile(f0.reshape(len(lat_out),1), len(lon_out))\n",
    "\n",
    "    # There should not be any NaNs, but replace in case\n",
    "    f_out[np.isnan(f_out)] = fillval  \n",
    "    \n",
    "    if (iforc == 'ts'):\n",
    "        vname = 'tas'\n",
    "    else: \n",
    "        vname = iforc\n",
    "\n",
    "    # Save output - this could be a function earlier in the code\n",
    "    sforc(gpath, vname, fname_out, lat_out, lon_out, time_out, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grid forcing zonal means by repeating at each point of longitude ###\n",
    "for iforc in forcings:\n",
    "    \n",
    "    # Load appropriate file & create right time vector\n",
    "    pN = xr.open_dataset(spath + iforc + fnameLF_in) \n",
    "    time_out  = time_m  # using day of year\n",
    "    fname_out = fnameLF_out\n",
    "    \n",
    "    # Create a zero array to store the forcing files\n",
    "    f_out = np.zeros((len(time_out), len(lat_out), len(lon_out)))\n",
    "             \n",
    "    # At every time step \n",
    "    for itime in np.arange(0,len(time_out)):\n",
    "        # Interpolate zonal mean to grid latitude\n",
    "        f0 = np.interp(lat_out, pN.lat, pN[iforc][itime,:])\n",
    "        f0 = low_filter(f0, t_coupe = 80)\n",
    "        \n",
    "        #### IDEALIZED WARMING\n",
    "        if (iforc == 'ts'):\n",
    "            f0 = low_filter(f0, t_coupe = 80)\n",
    "            scale_lat = (1-np.cos(np.max([np.zeros(len(lat_out)),(lat_out-40)/20], axis = 0)* np.pi/2))\n",
    "            scale_time = (np.cos((itime-1)/11 * 2 *np.pi)+1)/2\n",
    "            f0 = f0 - scale_lat * scale_time * 8\n",
    "\n",
    "        #### WARMING\n",
    "        #if (iforc == 'ts'):\n",
    "        #    f0 = low_filter(f0, t_coupe = 80) + 4\n",
    "        #    print('Temperature increased')\n",
    "        #if (iforc == 'rlds'):\n",
    "        #    f0 = low_filter(f0, t_coupe = 80) + 8.5\n",
    "        #    print('LW increased')\n",
    "        \n",
    "        # Repeat the profile everywhere in our domain\n",
    "        f_out[itime, :, :] = np.tile(f0.reshape(len(lat_out),1), len(lon_out))\n",
    "\n",
    "    # There should not be any NaNs, but replace in case\n",
    "    f_out[np.isnan(f_out)] = fillval  \n",
    "    \n",
    "    if (iforc == 'ts'):\n",
    "        vname = 'tas'\n",
    "    else: \n",
    "        vname = iforc\n",
    "\n",
    "    # Save output - this could be a function earlier in the code\n",
    "    sforc(gpath, vname, fname_out, lat_out, lon_out, time_out, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grid and scale zonal means associated with precipitation ###\n",
    "for iforc in scaledF:\n",
    "\n",
    "    # Load appropriate file & create right time vector\n",
    "    pN = xr.open_dataset(spath + iforc + fnameLF_in) \n",
    "    time_out  = time_m  # using day of year\n",
    "    fname_out = '_scaled' + fnameLF_out\n",
    "\n",
    "    # Load the information for scaling the precipitation\n",
    "    ocedim = xr.open_dataset('./model_ocean_widths_sq.nc')\n",
    "    rM2O =  ocedim.mwidth / ocedim.owidth # calculate ratio\n",
    "\n",
    "    # Interpolate scaling to grid latitude\n",
    "    r0 = np.interp(lat_out, ocedim.lat, rM2O)\n",
    "\n",
    "    # Create a zero array to store the forcing files\n",
    "    f_out = np.zeros((len(time_out), len(lat_out), len(lon_out)))\n",
    "\n",
    "    # At every time step (xarray way of doing so?)\n",
    "    for itime in np.arange(0,len(time_out)):\n",
    "        # Interpolate zonal mean to grid latitude\n",
    "        f0 = np.interp(lat_out, pN.lat, pN[iforc][itime,:])\n",
    "\n",
    "        # Scale mean precipitation to area in model vs. real ocean\n",
    "        fS = f0 / r0 # CST PRECIPITATION !!!\n",
    "        fS = np.full(np.shape(f0), np.mean(fS))\n",
    "\n",
    "        # Repeat the profile everywhere in our domain\n",
    "        f_out[itime, :, :] = np.tile(fS.reshape(len(lat_out),1), len(lon_out))\n",
    "\n",
    "    # There should not be any NaNs, but replace in case\n",
    "    f_out[np.isnan(f_out)] = fillval  \n",
    "\n",
    "    vname = iforc\n",
    "        \n",
    "    # Save output \n",
    "    sforc(gpath, vname, fname_out, lat_out, lon_out, time_out, f_out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmip6_omz2 [~/.conda/envs/cmip6_omz2/]",
   "language": "python",
   "name": "conda_cmip6_omz2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
